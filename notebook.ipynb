{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The filename, directory name, or volume label syntax is incorrect.\n",
      "The filename, directory name, or volume label syntax is incorrect.\n",
      "The filename, directory name, or volume label syntax is incorrect.\n",
      "The filename, directory name, or volume label syntax is incorrect.\n",
      "The filename, directory name, or volume label syntax is incorrect.\n",
      "The filename, directory name, or volume label syntax is incorrect.\n",
      "The filename, directory name, or volume label syntax is incorrect.\n",
      "The filename, directory name, or volume label syntax is incorrect.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!'{sys.executable}' -m pip install --upgrade pip\n",
    "!'{sys.executable}' -m pip install gurobipy\n",
    "!'{sys.executable}' -m pip install cvxpy\n",
    "!'{sys.executable}' -m pip install numpy\n",
    "!'{sys.executable}' -m pip install jupyter-matlab-proxy\n",
    "!'{sys.executable}' -m pip install matplotlib\n",
    "!'{sys.executable}' -m pip install multiprocess\n",
    "!'{sys.executable}' -m pip install matlabengine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic probability distribution histogram code + some helper functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "#import multiprocessing as mp\n",
    "import multiprocess as mp\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "def push_multinomial(n, k, occ=1):\n",
    "    return math.lgamma(n + k * occ + 1) - math.lgamma(n + 1) - occ * math.lgamma(k + 1)\n",
    "\n",
    "class DistHistogram:\n",
    "    def __init__(self, hist = defaultdict(int)):\n",
    "        self.hist = hist\n",
    "\n",
    "    # If the histogram actually represents a prob distribution\n",
    "    def check_integrity(self):\n",
    "        if not math.isclose(1.0, sum(self.hist[p] * p for p in self.hist)):\n",
    "            raise Exception(\"Bad histogram: {}\".format(str(self.hist)))\n",
    "\n",
    "    # Generate a fingerprint\n",
    "    def generate_fingerprint(self, k):\n",
    "        self.check_integrity()\n",
    "        n = sum(self.hist[p] for p in self.hist)\n",
    "        dist = np.concatenate([[p] * self.hist[p] for p in self.hist])\n",
    "        hist = np.random.multinomial(k, dist, size=1)\n",
    "        unique, counts = np.unique(hist, return_counts=True)\n",
    "        fingerprint = dict(zip(unique, counts))\n",
    "        if (zero := n - sum(fingerprint[f] for f in fingerprint)) != 0:\n",
    "            fingerprint[0] = zero\n",
    "        return fingerprint\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(hist)\n",
    "\n",
    "# Get true probability of obtaining a fingerprint \n",
    "# Speedup calculation with vectorization\n",
    "def get_probabilities(dists, fingerprint):\n",
    "    # Needs to have all distributions of the same ??-point structure\n",
    "    pts = {len(dist.hist) for dist in dists}\n",
    "    if len(pts) > 1:\n",
    "        raise Exception(\"All distributions need to have the same ??-point structure\")\n",
    "    k, pts = sum(fingerprint[f] * f for f in fingerprint), pts.pop()\n",
    "    log_zero_arr = lambda : np.full((1, m), -np.inf, dtype=float)\n",
    "\n",
    "    m = len(dists)\n",
    "    lps, ys = np.log(np.transpose([list(dist.hist.keys()) for dist in dists])), np.array([list(dist.hist.values()) for dist in dists])\n",
    "    coefficients = np.full((1, m), math.lgamma(k + 1))\n",
    "    for f in fingerprint:\n",
    "        coefficients -= fingerprint[f] * math.lgamma(f + 1)\n",
    "    for y in np.transpose(ys):\n",
    "        coefficients += np.vectorize(math.lgamma)(y + 1)\n",
    "    dp = defaultdict(log_zero_arr, {np.zeros(pts).tobytes(): coefficients})\n",
    "\n",
    "    # Partition lazy generator\n",
    "    def partition(size, array, value, occ):\n",
    "        ind = array.size\n",
    "        if ind == pts - 1:\n",
    "            i = size\n",
    "            new_value = value - math.lgamma(i + 1) + occ * i * lps[ind]\n",
    "            new_array = np.concatenate([array, [i]])\n",
    "            yield (new_array, new_value)\n",
    "        else:\n",
    "            for i in range(size + 1):\n",
    "                new_value = value - math.lgamma(i + 1) + occ * i * lps[ind]\n",
    "                new_array = np.concatenate([array, [i]])\n",
    "                yield from partition(size - i, new_array, new_value, occ)\n",
    "\n",
    "    for occ, frq in fingerprint.items():\n",
    "        new_dp = defaultdict(log_zero_arr)\n",
    "        for arr, val in partition(frq, np.array([]), np.full((1, m), 0.0, dtype=float), occ):\n",
    "            for prev_arr_byte, prev_val in dp.items():\n",
    "                prev_arr = np.frombuffer(prev_arr_byte)\n",
    "                idx = (arr + prev_arr).tobytes()\n",
    "                new_dp[idx] = np.logaddexp(new_dp[idx], val + prev_val)\n",
    "        dp = new_dp\n",
    "    ans = np.exp([dp[np.array(ys[i], dtype=float).tobytes()][0, i] for i in range(m)])\n",
    "    return ans\n",
    "\n",
    "def get_probabilities_no_multithread(dists, fingerprints):\n",
    "    return np.transpose([get_probabilities(dists, f) for f in fingerprints])\n",
    "\n",
    "def get_probabilities_multithread(dists, fingerprints):\n",
    "    pool = mp.Pool(processes=16)\n",
    "    return np.transpose(pool.starmap(get_probabilities, zip(itertools.repeat(dists), fingerprints)))\n",
    "\n",
    "def get_probabilities_nonuniform(dists, fingerprints):\n",
    "    #print(\"dists: \", [(a.hist, b.hist) for (a,b) in dists])\n",
    "    #print(\"fingerprints: \", fingerprints)\n",
    "\n",
    "    d1s = [a for (a,_) in dists]\n",
    "    d2s = [b for (_,b) in dists]\n",
    "\n",
    "    #print(\"d1s: \", str([d.hist for d in d1s]))\n",
    "    #print(\"d2s: \", str([d.hist for d in d2s]))\n",
    "\n",
    "    p1s = [get_probabilities(d1s, f1) for (f1, _) in fingerprints]\n",
    "    p2s = [get_probabilities(d2s, f2) for (_, f2) in fingerprints]\n",
    "    \"\"\"\n",
    "    print(\"p1s: \", p1s)\n",
    "    print(\"p2s: \", p2s)\n",
    "\n",
    "    print(\"--------- Begin Test ----------\")\n",
    "    for (f1, f2) in fingerprints:\n",
    "        print(\"Computing get_probabilities(\" + str([d.hist for d in d2s]) + \", \" + str(f2) + \"):\")\n",
    "        print(\"    Result: \" + str(get_probabilities(d2s, f2)))\n",
    "    print(\"---------- End Test -----------\")\n",
    "    \"\"\"\n",
    "\n",
    "    def jprob(k,j):\n",
    "        return np.exp(math.lgamma(k + 1) - math.lgamma(k - j + 1) - math.lgamma(j + 1) - k * math.log(2))\n",
    "\n",
    "    ans = []\n",
    "    for i in range(len(fingerprints)):\n",
    "        (f1, f2) = fingerprints[i]\n",
    "        j=sum(f1[f] * f for f in f1)\n",
    "        k=j + sum(f2[f] * f for f in f2)\n",
    "\n",
    "        ans.append([jprob(k,j)*a*b for a,b in zip(p1s[i],p2s[i])])\n",
    "    return np.transpose(ans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic tester + semilinear tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemilinearTester: #this might not be entirely clean if the worst case distribution changes due to probabilism\n",
    "    def __init__(self, c):\n",
    "        self.c = c\n",
    "\n",
    "    def get_coefficient(self, f):\n",
    "        return sum([cnt * self.c[0][i] for i, cnt in f[0].items()])+sum([cnt * self.c[1][i] for i, cnt in f[1].items()])\n",
    "\n",
    "    def optimize(self, lo, hi, fs, prob_hypo, prob_alts):\n",
    "        def binary_search(lo, hi, pred, eps=1e-9):\n",
    "            # assuming that pred(lo) is true and pred(hi) is false\n",
    "            while lo + eps < hi:\n",
    "                mi = (lo + hi) / 2\n",
    "                if pred(mi):\n",
    "                    lo = mi\n",
    "                else:\n",
    "                    hi = mi\n",
    "            return lo, hi\n",
    "\n",
    "        def predicate(t):\n",
    "            verdict = np.array([self.get_coefficient(f) >= t for f in fs], dtype=float)\n",
    "            t1 = (prob_hypo @ verdict)[0]\n",
    "            t2 = np.max(prob_alts @ (1 - verdict))\n",
    "            return t1 > t2\n",
    "    \n",
    "        self.lo, self.hi = binary_search(lo, hi, predicate)\n",
    "        verdict_lo = np.array([self.get_coefficient(f) >= self.lo for f in fs], dtype=float)\n",
    "        t1_lo = (prob_hypo @ verdict_lo)[0]\n",
    "        t2_lo = np.max(prob_alts @ (1 - verdict_lo))\n",
    "        verdict_hi = np.array([self.get_coefficient(f) >= self.hi for f in fs], dtype=float)\n",
    "        t1_hi = (prob_hypo @ verdict_hi)[0]\n",
    "        t2_hi = np.max(prob_alts @ (1 - verdict_hi))\n",
    "        # solve t1_lo + (t1_hi - t1_lo) * self.tb = t2_lo + (t2_hi - t2_lo) * self.tb\n",
    "        self.tb = (t1_lo - t2_lo) / ((t1_lo - t1_hi) - (t2_lo - t2_hi))\n",
    "        return np.log(t1_lo + (t1_hi - t1_lo) * self.tb)\n",
    "\n",
    "    def single_verdict(self, f):\n",
    "        if (coef := self.get_coefficient(f)) < self.lo:\n",
    "            return 0\n",
    "        elif coef > self.hi:\n",
    "            return 1\n",
    "        else:\n",
    "            return self.tb # this can be changed to a bernoulli sample with probability self.tb\n",
    "\n",
    "    def multiple_verdicts(self, fs):\n",
    "        return np.array([self.single_verdict(f) for f in fs], dtype=float)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating all alternative two-point distributions, sampling fingerprints, and generating probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n",
      "[[3.54375000e-07 1.59468750e-05 1.11628125e-04 2.12625000e-05\n",
      "  1.86046875e-04 1.48837500e-04 1.24031250e-05 6.97675781e-05\n",
      "  1.86046875e-04 3.10078125e-05 4.65117188e-05 3.72093750e-06\n",
      "  2.79070313e-06 3.72093750e-05 3.72093750e-05 2.79070313e-05\n",
      "  1.24031250e-05 7.44187500e-06 6.20156250e-07 3.10078125e-06\n",
      "  1.55039062e-06 1.37812500e-06 6.20156250e-06 1.86046875e-06\n",
      "  7.75195313e-07 1.24031250e-06 6.20156250e-07 5.90625000e-08\n",
      "  1.47656250e-07 1.10742188e-07 1.77187500e-07 4.42968750e-08\n",
      "  8.85937500e-08 5.90625000e-08 2.53125000e-08 3.16406250e-09\n",
      "  1.10742188e-09 1.84570312e-09 1.05468750e-09 3.95507813e-10\n",
      "  8.78906250e-11 9.76562500e-13 3.54375000e-05 6.37875000e-04\n",
      "  2.23256250e-03 4.96125000e-04 1.86046875e-03 1.86046875e-03\n",
      "  1.86046875e-04 2.79070313e-04 1.11628125e-03 2.48062500e-04\n",
      "  3.72093750e-04 3.72093750e-05 6.20156250e-05 1.24031250e-04\n",
      "  9.30234375e-05 6.20156250e-05 3.72093750e-05 4.13437500e-06\n",
      "  1.96875000e-06 8.85937500e-06 2.65781250e-06 2.21484375e-06\n",
      "  3.54375000e-06 1.77187500e-06 2.53125000e-07 1.10742188e-07\n",
      "  7.38281250e-08 3.16406250e-08 7.91015625e-09 9.76562500e-11\n",
      "  3.98671875e-04 3.72093750e-03 6.97675781e-03 1.86046875e-03\n",
      "  2.79070313e-03 3.72093750e-03 4.65117187e-04 1.16279297e-04\n",
      "  9.30234375e-04 3.10078125e-04 4.65117188e-04 6.20156250e-05\n",
      "  4.42968750e-05 3.32226562e-05 4.42968750e-05 2.65781250e-05\n",
      "  4.42968750e-06 6.92138672e-07 1.10742188e-06 5.53710938e-07\n",
      "  1.58203125e-07 2.19726563e-09 3.98671875e-04 3.72093750e-03\n",
      "  6.97675781e-03 1.86046875e-03 2.79070313e-03 3.72093750e-03\n",
      "  4.65117187e-04 1.16279297e-04 9.30234375e-04 3.10078125e-04\n",
      "  4.65117188e-04 6.20156250e-05 4.42968750e-05 3.32226562e-05\n",
      "  4.42968750e-05 2.65781250e-05 4.42968750e-06 6.92138672e-07\n",
      "  1.10742188e-06 5.53710938e-07 1.58203125e-07 2.19726563e-09\n",
      "  5.31562500e-03 2.79070312e-02 2.79070312e-02 9.30234375e-03\n",
      "  4.65117187e-03 9.30234375e-03 1.55039062e-03 6.64453125e-04\n",
      "  4.42968750e-04 6.64453125e-04 1.32890625e-04 2.76855469e-05\n",
      "  1.66113281e-05 5.53710937e-06 8.78906250e-08 1.77187500e-03\n",
      "  9.30234375e-03 9.30234375e-03 3.10078125e-03 1.55039062e-03\n",
      "  3.10078125e-03 5.16796875e-04 2.21484375e-04 1.47656250e-04\n",
      "  2.21484375e-04 4.42968750e-05 9.22851563e-06 5.53710938e-06\n",
      "  1.84570312e-06 2.92968750e-08 1.16279297e-02 3.48837891e-02\n",
      "  1.74418945e-02 7.75195312e-03 8.30566406e-04 3.32226562e-03\n",
      "  8.30566406e-04 6.92138672e-05 1.03820801e-04 4.15283203e-05\n",
      "  7.69042969e-07 1.55039062e-02 4.65117188e-02 2.32558594e-02\n",
      "  1.03359375e-02 1.10742187e-03 4.42968750e-03 1.10742187e-03\n",
      "  9.22851562e-05 1.38427734e-04 5.53710937e-05 1.02539062e-06\n",
      "  3.87597656e-03 1.16279297e-02 5.81396484e-03 2.58398437e-03\n",
      "  2.76855469e-04 1.10742187e-03 2.76855469e-04 2.30712891e-05\n",
      "  3.46069336e-05 1.38427734e-05 2.56347656e-07 4.65117187e-02\n",
      "  7.75195312e-02 1.66113281e-02 1.10742187e-02 1.38427734e-03\n",
      "  6.92138672e-04 1.53808594e-05 2.32558594e-02 3.87597656e-02\n",
      "  8.30566406e-03 5.53710937e-03 6.92138672e-04 3.46069336e-04\n",
      "  7.69042969e-06 4.65117187e-03 7.75195312e-03 1.66113281e-03\n",
      "  1.10742187e-03 1.38427734e-04 6.92138672e-05 1.53808594e-06\n",
      "  3.22998047e-02 2.76855469e-02 1.73034668e-03 2.30712891e-03\n",
      "  6.40869141e-05 4.84497070e-02 4.15283203e-02 2.59552002e-03\n",
      "  3.46069336e-03 9.61303711e-05 1.93798828e-02 1.66113281e-02\n",
      "  1.03820801e-03 1.38427734e-03 3.84521484e-05 3.22998047e-03\n",
      "  2.76855469e-03 1.73034668e-04 2.30712891e-04 6.40869141e-06\n",
      "  4.61425781e-02 1.73034668e-02 6.40869141e-04 2.76855469e-02\n",
      "  1.03820801e-02 3.84521484e-04 9.22851562e-03 3.46069336e-03\n",
      "  1.28173828e-04 1.31835937e-03 4.94384766e-04 1.83105469e-05\n",
      "  1.08146667e-02 1.20162964e-03 1.73034668e-02 1.92260742e-03\n",
      "  8.65173340e-03 9.61303711e-04 2.47192383e-03 2.74658203e-04\n",
      "  3.08990479e-04 3.43322754e-05 4.80651855e-03 3.20434570e-03\n",
      "  1.37329102e-03 3.43322754e-04 3.81469727e-05 2.40325928e-04\n",
      "  4.00543213e-04 2.28881836e-04 8.58306885e-05 1.90734863e-05\n",
      "  1.90734863e-06]]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "n, k = 10,10\n",
    "eps = 0.9\n",
    "fg_size = 20000\n",
    "\n",
    "hypo = DistHistogram({1/n: n})\n",
    "alts = []\n",
    "for q in range(1, n):\n",
    "    # x1 * q + x2 * (n - q) = 1\n",
    "    # (1 / n - x1) * q + (x2 - 1 / n) * (n - q) = eps\n",
    "    x1, x2 = (2 * q - n * eps) / (2 * n * q), (2 * n + n * eps - 2 * q) / (2 * n * (n - q))\n",
    "    if 0 < x1 <= 1 and 0 < x2 <= 1:\n",
    "        alts.append(DistHistogram({x1: q, x2: n - q}))\n",
    "\n",
    "def generate_fingerprint(n, k, mi, dct):\n",
    "    if n == 1:\n",
    "        dct[k] += 1\n",
    "        yield dict(dct)\n",
    "    else:\n",
    "        if n * (mi + 1) <= k:\n",
    "            yield from generate_fingerprint(n, k, mi + 1, copy.deepcopy(dct))\n",
    "        dct[mi] += 1\n",
    "        yield from generate_fingerprint(n - 1, k - mi, mi, dct)\n",
    "\n",
    "fingerprints = list(generate_fingerprint(n, k, 0, defaultdict(int)))\n",
    "\n",
    "def generate_fingerprint_nonuniform(n,k):\n",
    "    ans=[]\n",
    "    for j in range(0,k+1):\n",
    "        ans += [(f1,f2) for f1 in generate_fingerprint(2, j, 0, defaultdict(int)) for f2 in generate_fingerprint(n,k-j,0,defaultdict(int))]\n",
    "\n",
    "    return ans\n",
    "\n",
    "nonuniform_hypo = (DistHistogram({1/2: 2}), DistHistogram({1/n: n}))\n",
    "nonuniform_alts = (DistHistogram({1/2-eps/2: 1, 1/2+eps/2:1}), DistHistogram({1/n: n}))\n",
    "\n",
    "fingerprints_nonuniform = generate_fingerprint_nonuniform(n,k)\n",
    "\n",
    "# seen = set()\n",
    "# fingerprints = []\n",
    "# while len(fingerprints) < fg_size:\n",
    "#     f = hypo.generate_fingerprint(k)\n",
    "#     t = tuple(f.items())\n",
    "#     if t not in seen:\n",
    "#         seen.add(t)\n",
    "#         fingerprints.append(f)\n",
    "\n",
    "# fingerprints = [hypo.generate_fingerprint(k) for _ in range(fg_size)]\n",
    "print(len(fingerprints_nonuniform))\n",
    "#print(fingerprints_nonuniform)\n",
    "prob_hypo = get_probabilities_nonuniform([nonuniform_hypo], fingerprints_nonuniform)\n",
    "print(prob_hypo)\n",
    "prob_hypo = prob_hypo / prob_hypo.sum(axis=1)[:, np.newaxis] # normalization step\n",
    "# prob_alts = np.array([[alt.get_probability(fingerprint) for fingerprint in fingerprints] for alt in alts])\n",
    "prob_alts = get_probabilities_nonuniform([nonuniform_alts], fingerprints_nonuniform)\n",
    "prob_alts = prob_alts / prob_alts.sum(axis=1)[:, np.newaxis] # normalization step"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving linear program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tester:\n",
      "\n",
      "-1.1533220635953263\n",
      "-0.6062670028228467 -0.6062670019346683 0.1582159929645564\n",
      "chi_square:\n",
      "\n",
      "-1.1795495677261283\n",
      "10.666666666381275 10.666666667269453 0.25783328620558826\n"
     ]
    }
   ],
   "source": [
    "import matlab.engine\n",
    "import io\n",
    "\n",
    "# --2.783246248005155\n",
    "# -2.5430245416741255 deterministic tester\n",
    "\n",
    "lo, hi = -1e6, 1e6\n",
    "p = 2/(n+2)\n",
    "q = 0.5\n",
    "\n",
    "eng = matlab.engine.start_matlab()\n",
    "domain_fractions = matlab.double([p,1-p])\n",
    "probability_fractions = matlab.double([q,1-q])\n",
    "c_matlab = np.transpose(eng.get_coefs2(n * 1.0, k * 1.0, eps * 1.0,domain_fractions,probability_fractions, stdout=io.StringIO()))\n",
    "#if len(c_matlab) < k + 1:\n",
    "#    c_matlab = np.pad(c_matlab, (0, k + 1 - len(c_matlab)), 'constant')\n",
    "#print(c_matlab)\n",
    "matlab_tester = SemilinearTester(c_matlab)\n",
    "print(\"Our tester:\\n\")\n",
    "print(matlab_tester.optimize(lo, hi, fingerprints_nonuniform, prob_hypo, prob_alts))\n",
    "print(matlab_tester.lo, matlab_tester.hi, matlab_tester.tb)\n",
    "\n",
    "c_chi = np.array([[((i - (k*q) / (n*p)) ** 2 / ((k*q) / (n*p))) for i in range(k + 1)],[((i - (k*(1-q)) / (n*(1-p))) ** 2 / ((k*(1-q)) / (n*(1-p)))) for i in range(k + 1)]])\n",
    "chi_squared_tester = SemilinearTester(c_chi)\n",
    "print(\"chi_square:\\n\")\n",
    "print(chi_squared_tester.optimize(lo, hi, fingerprints_nonuniform, prob_hypo, prob_alts))\n",
    "print(chi_squared_tester.lo, chi_squared_tester.hi, chi_squared_tester.tb)\n",
    "\n",
    "#c_tv = np.array([abs(i - k / n) for i in range(k + 1)])\n",
    "#tv_tester = SemilinearTester(c_tv)\n",
    "#print(tv_tester.optimize(lo, hi, fingerprints, prob_hypo, prob_alts))\n",
    "#print(tv_tester.lo, tv_tester.hi, tv_tester.tb)\n",
    "\n",
    "#c_singleton = -np.array([i == 1 for i in range(k + 1)], dtype=float)\n",
    "#singleton_tester = SemilinearTester(c_singleton)\n",
    "#print(singleton_tester.optimize(lo, hi, fingerprints, prob_hypo, prob_alts))\n",
    "#print(singleton_tester.lo, singleton_tester.hi, singleton_tester.tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*list(zip(x.value, fingerprints)), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
